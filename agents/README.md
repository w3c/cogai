# Human Inspired Cognitive Agents
This describes work in progress on designing, implementing and testing artificial neural networks that mimic human cognition. Datasets and Python code resources will be added to this repository as work proceeds.

Large language models (LLMs) require vast training sets to cover the breadth of everyday knowledge needed for reasoning and prediction of text continuations.  I can't afford that and am limited to what can be achieved with a modest dataset.  My aim is to demonstrate neural architectures for memory, deliberative reasoning and continual learning. I therefore need to train on data based upon constrained language and semantics that will enable effective learning with a modest dataset and model size.

* ***We still have a lot to learn about learning!***
  
A gap of around 3-5 orders of magnitude exists between estimated human language inputs and the inputs to large language models. Children are estimated to have been exposed to between 6 to 60 million words by age 5, and 40 to 400 million words by age 20, whilst LLMs are trained on many trillions of words. A key difference between LLMs and human language acquisition is that human language is grounded to the real world.

See [Bridging the data gap between children and large language models](https://osf.io/qzbgx/download/), 2023, Michael C. Frank

Learning can be viewed as a combination of observation, instruction, experience and reflection. Cognitive agents can benefit from experience in trying to solve problems, rather than relying only on autoregressive training, i.e. masking to predict the next word given only the previous words.  I want to explore this using reinforcement learning, along with some measure of reflective thinking.

My first thought was to look at teaching materials for young children, and to consider the potential for using suitably prompted LLMs to generate training examples that can be supplemented as needed. Unfortunately, the generated examples assume a breadth of knowledge that implies a much larger dataset than is practical for my initial work.  Moreover, the teaching materials make frequent use of pictures and physical manipulation, something far too ambitious for my purpose.

Spatial reasoning and a grasp of everyday physics would involve a richer neural architecture and a large dataset for recognising objects, understanding scenes, and learning spatial manipulation skills. That is something for much better resourced research teams!  We therefore should limit ourselves to text-based semantics, and enabling learning through a combination of memorisation and manipulation.

It should be possible to provide digital worksheets as an alternative to visual perception and reasoning. This would be loosely equivalent to pencil and paper, enabling the cognitive agent to retrieve and augment structured information on the worksheet. Further study is needed to clarify how this would work, e.g. tokenisation and embeddings.

## Elementary Mathematics as a tractable domain

What seems practical is the way children are tought elementary mathematics, provided we exclude  instructions and exercises that involve diagrams, e.g. graphs and geometry. 

* The knowledge involved is largely standalone
* The teaching guides are available on line
* It involves rote memorisation
* It requires multi-step reasoning
* Examples can be readily generated by a script

See the [UK mathematics curriculum for year 1 to 6](https://www.gov.uk/government/publications/national-curriculum-in-england-mathematics-programmes-of-study/national-curriculum-in-england-mathematics-programmes-of-study) and [US core standards for mathematical proficiency](https://en.wikipedia.org/wiki/Common_Core#Mathematics_standards). I would exclude those parts that involve geometry, graphs and shapes. The agent would need to deal with simplified English, motivating a means to pre-train the language model. 

The starting point involves assertions, questions and answers:

* Counting in ones, twos, threes, fives and tens
* Working out the number that is one more or one less than a given number
* Adding and subtracting single digits
* Adding and subtracting numbers with multiple digits
* Competence with the multiplication table from 1 to 10
* Multiplication and long division

The US system has:

- Grades K-2: Concepts, skills, and problem solving related to addition and subtraction
- Grades 3-5: Concepts, skills, and problem solving related to multiplication and division of whole numbers and fractions
- Grade 6: Ratios and proportional relationships, and early algebraic expressions and equations
- Grade 7: Ratios and proportional relationships, and arithmetic of rational numbers
- Grade 8: Linear algebra and linear functions

Developing skills for elementary mathematics would be a good test of the neural architecture and algorithms, and could be followed by better resourced work on integrating commonsense and everyday reasoning using much larger datasets distilled from LLMs.  Support for richer mathematics would involve extending the tokeniser to support a subset of LaTex expressions. See [MathJax](https://docs.mathjax.org/en/latest/basic/mathjax.html) for rendering in web pages and [writing mathematical expressions](https://en.wikibooks.org/wiki/LaTeX/Mathematics) in GitHub Markdown.

## Neural Modules

A language encoder translates textual input to latent semantics (aka *working memory*). This is manipulated by a sequential reasoner associated with a vector database for explicit memory.  Language output decodes the latent semantics and is triggered by the reasoner.

* Tokenisations as words, symbols and digits
  * Separate digits to avoid an unlimited number of numeric tokens
  * Decoder inserts a space between tokens with a few exceptions
* Language model for encoding and asynchronous decoding
  * Retained feedbackward connections for context sensitivity
  * Using masking and model dropouts for initial training
* Factual knowledge for rote memorisation
  * Using the embedding learned for the language model
  * Create, recall, update and delete, plus iterative queries
* Single step application of the reasoner
  * Using the embedding learned for the language model
  * Simple transformations on the latent semantics
  * Trained via masked input
* Multi-step reasoning
  * Including working with factual knowledge from the memory module and relevant digital worksheets
  * Trained using model-based deep reinforcement learning with a parameterised decision tree and a means to assess progress.  A potential refinement would be to store failed approaches in episodic memory in case they can be successfully applied to different examples.
 
### Language Encoder

This mimics human language processing, which has been shown to be sequential, hierarchical and predictive. Text input is processed sequentially, token by token, using a small sliding window along with relative positional encoding to mimic the resource constraints of the phonological buffer, see [Baddeley and Hitch](https://en.wikipedia.org/wiki/Baddeley%27s_model_of_working_memory) (1974). To enable context sensitive decisions on part of speech, word sense, etc., the transformer layer output is retained and blended with the layer's input for the next step, mimicking human short term memory. This can be contrasted with conventional language models which are strictly feedforward and rely on a fixed context width. During training, the proposed architecture incrementally updates the computed loss, step by step, and initiates back propagation after every sentence.

### Language Decoder

This generates text output sequentially, token by token based upon the latent semantics, updating the latent semantics to indicate progress. Text generation is initiated by the reasoner and is executed asynchronously.

### Explicit Memory

Explicit memory is based upon a vector database whose operations are executed asynchronously, and update the latent semantics held in working memory. Explicit memory can be contrasted with implicit memory provided by the language model parameters. The operations include query, retrieval and update as well as the means to iterate through complex query results. Memories are subject to decay unless boosted, thereby mimicking the characteristics of human memory. This ensures that memories are more likely to be recalled if they have proven useful in the past.

### Sequential Reasoner

The reasoner is implemented as a feedforward network that is conditioned by the current state of working memory. Actions update working memory or initiate external actions, e.g. queries to explicit memory, or text generation. This is functionally equivalent to a production rule system. The reasoner is triggered by significant changes to working memory, e.g. when new input has been processed by the language encoder, or when working memory is updated by recall from explicit memory.

The reasoner is trained through deep reinforcement learning. The details are to be elucidated based upon study of the research literature on reinforcement learning. I envisage a model-based approach that can support reflective reasoning, e.g. to assess progress and decide when to abandon the current approach in favour of a potentially better approach, and how to break tasks down into subtasks, based upon a task taxonomy. In a symbolic system, this could be done using a decision tree with actions that include creating and mutating the rules as part of rule-sets.

## Plan of action

1. Develop a script to generate the dataset for training the language encoder and decoder
2. Implement the tokeniser
3. Implement and test the language encoder and decoder
4. Develop script for the single-step reasoning dataset
5. Implement and test the reasoner
6. Develop script for testing the memory module
7. Implement and test the memory module
8. Implement and test support for digital worksheets
9. Develop the script for multi-step reasoning dataset
10. Implement model-based deep reinforcement learning and test
11. Seek help with writing a paper to report the work

## Dataset for training initial language model

The tokeniser splits lines on line breaks, discarding empty lines. Tokens are specified in terms of regular expressions for words, digits, punctuation (":", ",", ";", ".", "?") and symbols ("+", "-", "*", "/", "=", ">", "<", ...)

An open question is whether to use words or digits for numbers, e.g.  "three hundred and seventy" vs "370".  I am inclined to use words since it is how we say numbers. However, we write them down as digits, and digits are needed for mathematical expressions. It would make sense to cover both.

Children learn about numbers by sorting objects by size, shape and colour, and identifying the number of objects in collections. A way to mimic that using simple collections of objects with differing characteristics would be helpful and points to a role for taxonomic knowledge.

A further challenge is enabling the cognitive agent to represent and manipulate the digits forming large numbers, e.g. units, tens, hundreds and thousands, along with intermediate results and carries. Children are shown how do this visually with pencil and paper. We need digital worksheets as a non-visual alternative for cognitive agents. 

Counting, simple addition and multiplication of single digits, e.g.

> Question: say 130? Answer: one hundred and thirty<br>
> Question: what is one hundred and thirty? Answer: 130<br>
> Question: count up from 1 to 10? Answer: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10<br>
> Question: count up by 10 from 10 to 50? 10, 20, 30, 40, 50, 60, 70, 80, 90, 100<br>
>
> Assert: 1 + 1 is 2<br>
> Assert: 2 + 2 is 4<br>
> Assert: 3 + 3  is 6<br>
>
> Assert: 100 + 1 is 101<br>
> Assert: 100 + 10 is 110<br>

and:

> Question: what is 1 before 6?  Answer: 5<br>
> Question: what is 2 after 6?  Answer: 8<br>
> Question: what is 1 plus 3? Answer: 4<br>
> Question: what is 2 times 3? Answer: 6<br>

where the keyword at the start indicates whether the text is an assertion, question or answer.  This allows the tokeniser to split the text up and categorise it correctly.  Each question is associated with its answer.  Values can be given as a comma separated list representing a sequence or a set. 

What is needed for the language model to generalise digit sequences to the concept of numbers? How can that be tested?  Should the key word and colon be passed to the model with the aim of it learning the differences between assertions, questions and answers?  How many examples are needed?

How can worked examples be given step by step, e.g. for multi-digit addition?

> To add 5 to 17. 17 has 1 for tens and 7 for units. We start with adding the units. Add 5 to 7 yielding 12.  This more than 10, so we find the remainder after substracting 10, yielding 2 carry 1.  We put 2 as the units for the answer. We move to the tens and add the value carried over from the previous step (i.e. 1). 1 + 1 is 2. We put 2 as the tens for the answer. Combining units tens yields the final answer 22.

That is far from ideal!   We first need to explain how to interpret digit sequences in terms of units, tens, hundreds, thousands, etc.  We need to explain how to treat this as a sequence of columns, single digit additions and carry overs. This is where the idea of worksheets may be helpful, serving in place of pencil and paper.

Microsoft Copilot explains how to break down the addition of 158,764 and 73 step by step as follows:

1. Write the numbers vertically
2. Start from the rightmost digit (units)
   Add 4 and 3: (4 + 3 = 7).
   Write down the 7 in the units place.
3. Move to the next digit (tens)
   Add 6 and 7: (6 + 7 = 13).
   Write down the 3 in the tens place and carry over the 1.
4. Continue to the next digit (hundreds)
   Add 8, 1 (from the carryover), and 3: (8 + 1 + 3 = 12).
   Write down the 2 in the hundreds place and carry over the 1.
5. Move to the thousands place
   Add 7, 1 (from the carryover), and 7: (7 + 1 + 7 = 15).
   Write down the 5 in the thousands place and carry over the 1.
6. Finally add the ten thousands place
   Add 5 and 1 (from the carryover): (5 + 1 = 6).
   Write down the 6 in the ten thousands place.
7. No more digits, so the sum of 158,764 and 73 is 158,837

The digital worksheet for this needs three lines for the pair of numbers to be added and the working result. The columns need to be associated with their role. We also need to remember the carry over from the previous column. The reasoner needs to be able to initialise the worksheet, and to access and update its values as the algorithm proceeds.

The memory module is used for rote memorisation such as addition of single digits, whilst the worksheets supplement working memory. How can we train the reasoner to use explicit memory and digital worksheets? How can we preload a worksheet, analogous to the teacher handing out printed sheets of paper?

*to be continued...*
